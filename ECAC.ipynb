{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ECAC.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/susanalima/CV-ONTOLOGY/blob/master/ECAC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0lwpLRbQGsq",
        "outputId": "61936200-f821-4921-8496-3968dba483eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import os\n",
        "import csv\n",
        "\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedShuffleSplit, cross_validate\n",
        "from sklearn import svm\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix, f1_score, make_scorer, balanced_accuracy_score, recall_score, precision_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 707,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgTowzoxSipx"
      },
      "source": [
        "#!unzip \"/content/drive/My Drive/ECAC/data.zip\" -d \"/content/drive/My Drive/ECAC/data\""
      ],
      "execution_count": 708,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mS_Pk-A8TCHC"
      },
      "source": [
        "mainDir = \"/content/drive/My Drive/ECAC/\"\n",
        "dataDir = mainDir + \"data/publicData/\"\n",
        "predictionsDir = mainDir + \"predictions/\"\n",
        "\n",
        "# directory for loan train data\n",
        "# format: loan_id;account_id;date;amount;duration;payments;status\n",
        "loanTrainDir = dataDir + \"loan_train.csv\"\n",
        "\n",
        "# directory for loan test data\n",
        "# format: loan_id;account_id;date;amount;duration;payments\n",
        "loanTestDir = dataDir + \"loan_test.csv\"\n",
        "\n",
        "# directory for account data\n",
        "# format: \"account_id\";\"district_id\";\"frequency\";\"date\"\n",
        "accountDir = dataDir + \"account.csv\"\n",
        "\n",
        "# directory for district data\n",
        "# format: code ;name ;region;no. of inhabitants;no. of municipalities with inhabitants < 499 ;no. of municipalities with inhabitants 500-1999;no. of municipalities with inhabitants 2000-9999 ;no. of municipalities with inhabitants >10000 ;no. of cities ;ratio of urban inhabitants ;average salary ;unemploymant rate '95 ;unemploymant rate '96 ;no. of enterpreneurs per 1000 inhabitants ;no. of commited crimes '95 ;no. of commited crimes '96 \n",
        "districtDir = dataDir + \"district.csv\""
      ],
      "execution_count": 709,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8hpCUPpV_X-"
      },
      "source": [
        "# read data from csv file in directory (dir), by default the delimiter is ';'\n",
        "# returns the data\n",
        "def read_from_file(dir, delimiter=';'):\n",
        "  # Create a dataframe from csv\n",
        "  df = pd.read_csv(dir, delimiter=delimiter)\n",
        "\n",
        "  c = df.select_dtypes(\"object\").columns.tolist()\n",
        "  print(c)\n",
        "  df= pd.get_dummies(df, columns=c)\n",
        "\n",
        "  # User list comprehension to create a list of lists from Dataframe rows\n",
        "  data = [list(row) for row in df.values]\n",
        "  # Insert Column names as first list in list of lists\n",
        "  #data.insert(0, df.columns.to_list())\n",
        "  return data, df\n",
        "\n",
        "# writes data to file in specified directory\n",
        "def write_to_file(dir, content):\n",
        "  with open(dir, \"w\") as f:\n",
        "      writer = csv.writer(f)\n",
        "      writer.writerows(content)"
      ],
      "execution_count": 710,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-0nMR39PwHA"
      },
      "source": [
        "def list_int(lst):\n",
        "  return [int(item) for item in lst]\n",
        "\n",
        "def list_of_lists_int(lst):\n",
        "  return [list_int(item) for item in lst]\n",
        "\n",
        "# get list with sublist of elements of every list in the list of lists\n",
        "# lst list of lists [[],[],[]]\n",
        "# start: start position of sublist\n",
        "# end: end position of sublist\n",
        "def get_elems_list_of_lists(lst, start, end):\n",
        "  return [item[start:end] for item in lst]\n",
        "\n",
        "# create one single list from list of lists\n",
        "def list_merge(a):\n",
        "  return list(itertools.chain.from_iterable(a))"
      ],
      "execution_count": 711,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJMFSZigdU0j"
      },
      "source": [
        "# splits data in two sets, train and test (suffles the data)\n",
        "def split_data_rand(data, labels, size=0.2):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(data, labels, shuffle=True, test_size=size) \n",
        "  return X_train, X_test, y_train, y_test "
      ],
      "execution_count": 712,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8tr0dkHZMy0"
      },
      "source": [
        "# runs default svm algorithm\n",
        "def svm_run(xTrain, xTest, yTrain, weights=\"balanced\", kernel=\"linear\", average=\"macro\"):\n",
        "\n",
        "  # normalize features between 0 and 1\n",
        "  xTrain = svm_normalize_features(xTrain)\n",
        "  xTest = svm_normalize_features(xTest)\n",
        "\n",
        "  svm_model = svm.SVC(kernel=kernel, class_weight=weights) \n",
        "  #Train the model using the training sets\n",
        "  svm_model.fit(xTrain, yTrain)\n",
        "  #Test the model using the testing sets\n",
        "  yPred = svm_model.predict(xTest)\n",
        "  return yPred\n",
        "\n",
        "\n",
        "# runs default rf algorithm\n",
        "def rf_run(xTrain, xTest, yTrain, weights=\"balanced\", average=\"macro\"):\n",
        "  # Instantiate model with 50 decision trees\n",
        "  rf_model = RandomForestClassifier(n_estimators = 50, class_weight=weights)\n",
        "  #Train the model using the training sets\n",
        "  rf_model.fit(xTrain, yTrain)\n",
        "  #Test the model using the testing sets\n",
        "  yPred = rf_model.predict(xTest)\n",
        "  return yPred\n",
        "\n",
        "# runs default mlp algorithm\n",
        "def mlp_run(xTrain, xTest, yTrain, weights=\"balanced\", average=\"macro\"):\n",
        "  mlp_model = MLPClassifier(\n",
        "      solver=\"lbfgs\", alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1\n",
        "  )\n",
        "  mlp_model.fit(xTrain, yTrain)\n",
        "  yPred = mlp_model.predict(xTest)\n",
        "  return yPred\n"
      ],
      "execution_count": 713,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdmiAHGU8W3L"
      },
      "source": [
        "# uses MinMaxScaler to normalize the features between 0 and 1 (required for svm)\n",
        "def svm_normalize_features(features):\n",
        "  #normalize between 0 and 1\n",
        "  scaler = MinMaxScaler() \n",
        "  features = scaler.fit_transform(features)\n",
        "  return features\n"
      ],
      "execution_count": 714,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eC9qASFEAK_q"
      },
      "source": [
        "# joins loans ids and predictions in list of lists\n",
        "def add_id_to_predictions(ids, predictions):\n",
        "  res = []\n",
        "  for i in range(len(ids)):\n",
        "    res.append([ids[i], predictions[i]])\n",
        "  return res\n",
        "\n",
        "# adds header to csv file as request for submission\n",
        "def add_header_to_results(results):\n",
        "  results.insert(0, ['Id','Predicted'])\n",
        "  return results"
      ],
      "execution_count": 715,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WASi7BA8giV"
      },
      "source": [
        "# first implementation of cross validation\n",
        "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html\n",
        "# https://scikit-learn.org/stable/modules/cross_validation.html\n",
        "def model_cross_validation(model, xTrain, yTest, cv, scoring):\n",
        "  return cross_validate(model, xTrain, yTest, cv=cv, scoring=scoring, return_estimator=True)\n",
        "\n",
        "\n",
        "# cross validation for svm\n",
        "def svm_cross_validation(xTrain, yTrain, cv, scoring):\n",
        "  xTrain = svm_normalize_features(xTrain)\n",
        "  clf = svm.SVC(kernel='linear', class_weight=\"balanced\")\n",
        "  return model_cross_validation(clf, xTrain, yTrain, cv, scoring)\n",
        "\n",
        "\n",
        "# cross validation for svm\n",
        "def rf_cross_validation(xTrain, yTrain, cv, scoring):\n",
        "  clf = RandomForestClassifier(n_estimators=50, class_weight=\"balanced\")\n",
        "  return model_cross_validation(clf, xTrain, yTrain, cv, scoring)"
      ],
      "execution_count": 716,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17ge1aOkBIlb",
        "outputId": "3cf78768-e2a1-4d02-e8f9-798e3dd92ae1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "accountData, accountDataDF = read_from_file(accountDir)\n",
        "districtData, districtDataDF = read_from_file(districtDir)"
      ],
      "execution_count": 717,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['frequency']\n",
            "['name ', 'region', \"unemploymant rate '95 \", \"no. of commited crimes '95 \"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q99tLcRf_uwQ",
        "outputId": "47a69820-4ff8-4fe4-8e1e-a5eaedc7c1bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# read loan train data from corresponding directory\n",
        "loanTrainData, loanTrainDataDF = read_from_file(loanTrainDir)\n",
        "\n",
        "# read loan test data from # read loan train data from corresponding directory\n",
        "loanTestData, loanTestDataDF = read_from_file(loanTestDir)\n",
        "loanTestData = get_elems_list_of_lists(loanTestData, 0, 6)\n",
        "#loanTestData = list_of_lists_int(loanTestData)"
      ],
      "execution_count": 718,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[]\n",
            "[]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE4htiI4Bqd2"
      },
      "source": [
        "loanTrainDataDF = pd.merge(loanTrainDataDF, accountDataDF, on='account_id', how='inner')\n",
        "loanTrainDataDF = loanTrainDataDF.drop(['status', 'loan_id', 'account_id'], axis=1)\n",
        "#loanTrainDataDF = pd.merge(loanTrainDataDF, districtDataDF, left_on='district_id', right_on='code ', how='inner')\n",
        "#loanTrainDataDF = loanTrainDataDF.drop(['code '], axis=1)\n",
        "\n",
        "loanTestDataDF = pd.merge(loanTestDataDF, accountDataDF, on='account_id', how='inner')\n",
        "loanTestDataDF = loanTestDataDF.drop(['status', 'loan_id', 'account_id'], axis=1)\n",
        "#loanTestDataDF = pd.merge(loanTestDataDF, districtDataDF, left_on='district_id', right_on='code ', how='inner')\n",
        "#loanTestDataDF = loanTestDataDF.drop(['code '], axis=1)"
      ],
      "execution_count": 719,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXTwU5o88qG6"
      },
      "source": [
        "# loan train ids\n",
        "loanTrainIds = get_elems_list_of_lists(loanTrainData, 0, 1)\n",
        "loanTrainIds = list_merge(loanTrainIds)\n",
        "\n",
        "# loan train \"features\"\n",
        "loanTrainX = loanTrainDataDF.values\n",
        "\n",
        "# loan train labels\n",
        "loanTrainY = get_elems_list_of_lists(loanTrainData, 6, 7)\n",
        "loanTrainY = list_merge(loanTrainY)\n",
        "\n",
        "# loan test ids\n",
        "loanTestIds = get_elems_list_of_lists(loanTestData, 0, 1)\n",
        "loanTestIds = list_merge(loanTestIds)\n",
        "\n",
        "# loan test \"features\"\n",
        "loanTestX = loanTestDataDF.values"
      ],
      "execution_count": 720,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jO2zesyW_xnB"
      },
      "source": [
        "svmPredictions = svm_run(loanTrainX, loanTestX, loanTrainY)\n",
        "\n",
        "\n",
        "rfPredictions = rf_run(loanTrainX, loanTestX, loanTrainY)\n",
        "mlpPredictions = mlp_run(loanTrainX, loanTestX, loanTrainY)\n",
        "\n",
        "svmResults = add_id_to_predictions(loanTestIds, svmPredictions)\n",
        "svmResults = add_header_to_results(svmResults)\n",
        "\n",
        "rfResults = add_id_to_predictions(loanTestIds, rfPredictions)\n",
        "rfResults = add_header_to_results(rfResults)\n",
        "\n",
        "mlpResults = add_id_to_predictions(loanTestIds, mlpPredictions)\n",
        "mlpResults = add_header_to_results(mlpResults)\n"
      ],
      "execution_count": 721,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QES45nQ8G-nJ"
      },
      "source": [
        "write_to_file(predictionsDir + \"svm.csv\", svmResults)\n",
        "write_to_file(predictionsDir + \"rf.csv\", rfResults)\n",
        "write_to_file(predictionsDir + \"mlp.csv\", mlpResults)"
      ],
      "execution_count": 722,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4I_EhBCGeIFh",
        "outputId": "a1ab8ef7-5d5b-478f-9b3a-3537fba497d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#cv = 10\n",
        "\n",
        "nSplits=10  \n",
        "cv = StratifiedShuffleSplit(n_splits=nSplits, test_size=0.2, random_state=0)\n",
        "\n",
        "scoring = ['accuracy', 'balanced_accuracy']\n",
        "\n",
        "svm_scores = svm_cross_validation(loanTrainX, loanTrainY, cv, scoring )\n",
        "print(\"svm cross validation scores\")\n",
        "print(svm_scores['test_accuracy'])\n",
        "print(svm_scores['test_balanced_accuracy'])\n",
        "\n",
        "rf_scores = rf_cross_validation(loanTrainX, loanTrainY, cv, scoring )\n",
        "print(\"\\nrf cross validation scores\")\n",
        "print(rf_scores['test_accuracy'])\n",
        "print(rf_scores['test_balanced_accuracy'])"
      ],
      "execution_count": 723,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "svm cross validation scores\n",
            "[0.51515152 0.57575758 0.63636364 0.59090909 0.62121212 0.59090909\n",
            " 0.59090909 0.59090909 0.53030303 0.48484848]\n",
            "[0.53216374 0.56725146 0.60233918 0.57602339 0.54678363 0.57602339\n",
            " 0.57602339 0.43567251 0.44736842 0.51461988]\n",
            "\n",
            "rf cross validation scores\n",
            "[0.86363636 0.81818182 0.83333333 0.86363636 0.84848485 0.87878788\n",
            " 0.84848485 0.86363636 0.87878788 0.86363636]\n",
            "[0.54678363 0.47368421 0.48245614 0.5        0.5380117  0.60233918\n",
            " 0.49122807 0.5        0.60233918 0.5       ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}